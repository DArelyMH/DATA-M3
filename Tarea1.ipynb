{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:crimson\">Tarea</h1>\n",
    "\n",
    "* Entrenar un modelo Lasso con GridSearchCV usando un pipeline de polinomios de segundo grado\n",
    "* Graficar coeficientes \"significativos\"\n",
    "* Revisar cuantos parámetros son mayores a 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hint: usando parámetros dentro de un pipeline\n",
    "# para usar dentro de GridSearchCV\n",
    "pipe = Pipeline([\n",
    "    \"paso1\": PolynomialFeatures(),\n",
    "    \"model\": LinearRegression()\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"model__normalize\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan todas las librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from numpy.random import uniform\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KIMBERA MF Equity</th>\n",
       "      <th>GAPB MF Equity</th>\n",
       "      <th>CEMEXCPO MF Equity</th>\n",
       "      <th>ASURB MF Equity</th>\n",
       "      <th>GFNORTEO MF Equity</th>\n",
       "      <th>KOFUBL MF Equity</th>\n",
       "      <th>AC* MF Equity</th>\n",
       "      <th>LABB MF Equity</th>\n",
       "      <th>FEMSAUBD MF Equity</th>\n",
       "      <th>OMAB MF Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>MEGACPO MF Equity</th>\n",
       "      <th>GCC* MF Equity</th>\n",
       "      <th>BIMBOA MF Equity</th>\n",
       "      <th>GMEXICOB MF Equity</th>\n",
       "      <th>GCARSOA1 MF Equity</th>\n",
       "      <th>TLEVICPO MF Equity</th>\n",
       "      <th>ALFAA MF Equity</th>\n",
       "      <th>BSMXB MF Equity</th>\n",
       "      <th>PINFRA* MF Equity</th>\n",
       "      <th>MEXBOL INDEX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>40.37</td>\n",
       "      <td>152.05</td>\n",
       "      <td>8.72</td>\n",
       "      <td>243.89</td>\n",
       "      <td>94.99</td>\n",
       "      <td>123.90</td>\n",
       "      <td>104.68</td>\n",
       "      <td>13.85</td>\n",
       "      <td>161.63</td>\n",
       "      <td>83.61</td>\n",
       "      <td>...</td>\n",
       "      <td>64.19</td>\n",
       "      <td>44.81</td>\n",
       "      <td>45.95</td>\n",
       "      <td>36.79</td>\n",
       "      <td>70.98</td>\n",
       "      <td>94.34</td>\n",
       "      <td>34.10</td>\n",
       "      <td>30.25</td>\n",
       "      <td>202.73</td>\n",
       "      <td>42977.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>39.16</td>\n",
       "      <td>148.57</td>\n",
       "      <td>8.43</td>\n",
       "      <td>238.29</td>\n",
       "      <td>91.79</td>\n",
       "      <td>120.29</td>\n",
       "      <td>102.09</td>\n",
       "      <td>14.41</td>\n",
       "      <td>157.62</td>\n",
       "      <td>81.77</td>\n",
       "      <td>...</td>\n",
       "      <td>64.45</td>\n",
       "      <td>43.51</td>\n",
       "      <td>45.02</td>\n",
       "      <td>35.71</td>\n",
       "      <td>69.83</td>\n",
       "      <td>92.62</td>\n",
       "      <td>33.74</td>\n",
       "      <td>29.46</td>\n",
       "      <td>202.93</td>\n",
       "      <td>42113.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>38.89</td>\n",
       "      <td>147.93</td>\n",
       "      <td>8.31</td>\n",
       "      <td>233.03</td>\n",
       "      <td>91.72</td>\n",
       "      <td>118.82</td>\n",
       "      <td>101.12</td>\n",
       "      <td>13.77</td>\n",
       "      <td>157.80</td>\n",
       "      <td>81.58</td>\n",
       "      <td>...</td>\n",
       "      <td>63.16</td>\n",
       "      <td>43.51</td>\n",
       "      <td>45.77</td>\n",
       "      <td>36.45</td>\n",
       "      <td>70.70</td>\n",
       "      <td>91.89</td>\n",
       "      <td>33.99</td>\n",
       "      <td>29.72</td>\n",
       "      <td>203.56</td>\n",
       "      <td>42041.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>39.13</td>\n",
       "      <td>146.99</td>\n",
       "      <td>8.29</td>\n",
       "      <td>231.97</td>\n",
       "      <td>91.63</td>\n",
       "      <td>120.32</td>\n",
       "      <td>102.50</td>\n",
       "      <td>13.65</td>\n",
       "      <td>156.37</td>\n",
       "      <td>82.03</td>\n",
       "      <td>...</td>\n",
       "      <td>63.27</td>\n",
       "      <td>43.51</td>\n",
       "      <td>45.97</td>\n",
       "      <td>35.57</td>\n",
       "      <td>70.47</td>\n",
       "      <td>90.41</td>\n",
       "      <td>33.65</td>\n",
       "      <td>29.67</td>\n",
       "      <td>199.80</td>\n",
       "      <td>41691.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>39.16</td>\n",
       "      <td>141.32</td>\n",
       "      <td>7.64</td>\n",
       "      <td>230.71</td>\n",
       "      <td>89.54</td>\n",
       "      <td>120.20</td>\n",
       "      <td>101.16</td>\n",
       "      <td>13.25</td>\n",
       "      <td>155.14</td>\n",
       "      <td>80.94</td>\n",
       "      <td>...</td>\n",
       "      <td>62.78</td>\n",
       "      <td>42.76</td>\n",
       "      <td>46.18</td>\n",
       "      <td>35.01</td>\n",
       "      <td>68.15</td>\n",
       "      <td>90.23</td>\n",
       "      <td>31.46</td>\n",
       "      <td>28.50</td>\n",
       "      <td>196.75</td>\n",
       "      <td>40661.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KIMBERA MF Equity  GAPB MF Equity  CEMEXCPO MF Equity  \\\n",
       "DATE                                                                \n",
       "2016-01-01              40.37          152.05                8.72   \n",
       "2016-01-04              39.16          148.57                8.43   \n",
       "2016-01-05              38.89          147.93                8.31   \n",
       "2016-01-06              39.13          146.99                8.29   \n",
       "2016-01-07              39.16          141.32                7.64   \n",
       "\n",
       "            ASURB MF Equity  GFNORTEO MF Equity  KOFUBL MF Equity  \\\n",
       "DATE                                                                \n",
       "2016-01-01           243.89               94.99            123.90   \n",
       "2016-01-04           238.29               91.79            120.29   \n",
       "2016-01-05           233.03               91.72            118.82   \n",
       "2016-01-06           231.97               91.63            120.32   \n",
       "2016-01-07           230.71               89.54            120.20   \n",
       "\n",
       "            AC* MF Equity  LABB MF Equity  FEMSAUBD MF Equity  OMAB MF Equity  \\\n",
       "DATE                                                                            \n",
       "2016-01-01         104.68           13.85              161.63           83.61   \n",
       "2016-01-04         102.09           14.41              157.62           81.77   \n",
       "2016-01-05         101.12           13.77              157.80           81.58   \n",
       "2016-01-06         102.50           13.65              156.37           82.03   \n",
       "2016-01-07         101.16           13.25              155.14           80.94   \n",
       "\n",
       "            ...  MEGACPO MF Equity  GCC* MF Equity  BIMBOA MF Equity  \\\n",
       "DATE        ...                                                        \n",
       "2016-01-01  ...              64.19           44.81             45.95   \n",
       "2016-01-04  ...              64.45           43.51             45.02   \n",
       "2016-01-05  ...              63.16           43.51             45.77   \n",
       "2016-01-06  ...              63.27           43.51             45.97   \n",
       "2016-01-07  ...              62.78           42.76             46.18   \n",
       "\n",
       "            GMEXICOB MF Equity  GCARSOA1 MF Equity  TLEVICPO MF Equity  \\\n",
       "DATE                                                                     \n",
       "2016-01-01               36.79               70.98               94.34   \n",
       "2016-01-04               35.71               69.83               92.62   \n",
       "2016-01-05               36.45               70.70               91.89   \n",
       "2016-01-06               35.57               70.47               90.41   \n",
       "2016-01-07               35.01               68.15               90.23   \n",
       "\n",
       "            ALFAA MF Equity  BSMXB MF Equity  PINFRA* MF Equity  MEXBOL INDEX  \n",
       "DATE                                                                           \n",
       "2016-01-01            34.10            30.25             202.73      42977.50  \n",
       "2016-01-04            33.74            29.46             202.93      42113.70  \n",
       "2016-01-05            33.99            29.72             203.56      42041.68  \n",
       "2016-01-06            33.65            29.67             199.80      41691.19  \n",
       "2016-01-07            31.46            28.50             196.75      40661.57  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#se buscan los datos y se muestran\n",
    "ipc_path = \"ipc.xlsx\" \n",
    "market = pd.read_excel(ipc_path, index_col=0)\n",
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmkt = market.pct_change().dropna()\n",
    "\n",
    "Xall = Rmkt.drop(\"MEXBOL INDEX\", axis=1)\n",
    "Xall = Xall.join(Rmkt[\"MEXBOL INDEX\"].shift(1)).dropna()\n",
    "\n",
    "Xtrain = Xall.drop(\"MEXBOL INDEX\", axis=1)\n",
    "ytrain = Xall[\"MEXBOL INDEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se defdinen los periodos del entrenamiento y la prueba\n",
    "test_period = \"2019-12\"\n",
    "Xtest, ytest = Xtrain[test_period:], ytrain[test_period:]\n",
    "Xtrain, ytrain = Xtrain[:\"2019-11\":], ytrain[:\"2019-11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((646,), (25,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se emplea una alpha uniforme que sirva para entrenar el modelo\n",
    "alpha_list = uniform(0.0001, 0.000001, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el Pipeline del modelo\n",
    "pipe = Pipeline([\n",
    "    (\"paso1\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", Lasso())\n",
    "])\n",
    "\n",
    "# Se determinan los parámetros a usar para el entrenamiento\n",
    "params = {\n",
    "    \"model__normalize\": [True, False],\n",
    "    \"model__alpha\": alpha_list,\n",
    "    \"model__fit_intercept\": [True, False]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning:\n",
      "\n",
      "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se determina el SearcCV con lo anteriormente definido\n",
    "SEARCH = GridSearchCV(estimator = pipe,\n",
    "                    param_grid = dict(params),\n",
    "                    cv = 5)\n",
    "gs=SEARCH.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 8.641139163738937e-06,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__normalize': False}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.64426220e-03, -1.03632358e-03, -7.49565090e-04,  4.87368300e-04,\n",
       "       -1.21298939e-03,  8.97024736e-04,  1.36965895e-03,  9.44704713e-04,\n",
       "       -1.67132536e-04,  5.44975876e-03,  1.58652230e-03,  6.64006721e-04,\n",
       "        1.91913786e-03, -1.19126144e-03, -3.26819639e-03, -1.23511056e-03,\n",
       "        7.08990990e-05, -1.67132536e-04,  9.26298478e-04, -1.12948586e-03,\n",
       "       -2.10643042e-03,  1.73707986e-03, -1.67132536e-04,  1.85752357e-03,\n",
       "       -9.60331465e-05])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filt = gs.best_estimator_.named_steps['model'].coef_ > 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.04078219,  0.03081593, -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.00079319, -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.00523065, -0.        ,\n",
       "        0.        ,  0.03756816,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.01959081,  0.        ,  0.        , -0.01059117,\n",
       "        0.03595327, -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gs.best_estimator_.named_steps['model'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00016713253627155132"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.named_steps['model'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 8.641139163738937e-06,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__normalize': False}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
