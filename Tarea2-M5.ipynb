{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv49WzWCgeg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8kin6vQgkeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_cv, X_test = X_test[7000:], X_test[:7000]\n",
        "y_cv, y_test = y_test[7000:], y_test[:7000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ey280t2g_q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "tensorflow_c = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop_callback = tf.keras.callbacks.EarlyStopping(patience=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaTVjiNpkI9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def m_tarea(activation=\"relu\", optimizer=\"adadelta\", layers=(300, 100)):\n",
        "  Xin = Input(shape=(28, 28))\n",
        "  X = Flatten()(Xin)\n",
        "  for layer in layers:\n",
        "    X = Dense(layer, activation=activation)(X)\n",
        "  X = Dense(10, activation=\"softmax\")(X)\n",
        "  model = Model(inputs=Xin, outputs=X)\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9MjAT4_klw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b14b8b92-da99-462d-f8d3-1d1740cbd4fb"
      },
      "source": [
        "model = m_tarea(layers=(300, 100, 30, 30,30, 30,30, 25,25, 25,25, 25,25, 25,25, 25, 15,10, 5, 10))\n",
        "\n",
        "model.fit(x=X_train , y=y_train,\n",
        "          epochs=800,\n",
        "          validation_data=(X_cv, y_cv),\n",
        "           callbacks=[tensorflow_c])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.3427 - accuracy: 0.1138 - val_loss: 2.2803 - val_accuracy: 0.1350\n",
            "Epoch 2/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.2410 - accuracy: 0.1631 - val_loss: 2.2155 - val_accuracy: 0.1510\n",
            "Epoch 3/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.1863 - accuracy: 0.1485 - val_loss: 2.1742 - val_accuracy: 0.1517\n",
            "Epoch 4/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.1495 - accuracy: 0.1644 - val_loss: 2.1434 - val_accuracy: 0.1597\n",
            "Epoch 5/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.1206 - accuracy: 0.1729 - val_loss: 2.1175 - val_accuracy: 0.1660\n",
            "Epoch 6/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0972 - accuracy: 0.1890 - val_loss: 2.0969 - val_accuracy: 0.1803\n",
            "Epoch 7/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0786 - accuracy: 0.2056 - val_loss: 2.0804 - val_accuracy: 0.1927\n",
            "Epoch 8/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0637 - accuracy: 0.2146 - val_loss: 2.0673 - val_accuracy: 0.2040\n",
            "Epoch 9/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0516 - accuracy: 0.2214 - val_loss: 2.0562 - val_accuracy: 0.2120\n",
            "Epoch 10/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0410 - accuracy: 0.2281 - val_loss: 2.0466 - val_accuracy: 0.2237\n",
            "Epoch 11/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0319 - accuracy: 0.2353 - val_loss: 2.0381 - val_accuracy: 0.2273\n",
            "Epoch 12/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0235 - accuracy: 0.2373 - val_loss: 2.0306 - val_accuracy: 0.2333\n",
            "Epoch 13/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0158 - accuracy: 0.2383 - val_loss: 2.0236 - val_accuracy: 0.2363\n",
            "Epoch 14/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0087 - accuracy: 0.2393 - val_loss: 2.0167 - val_accuracy: 0.2393\n",
            "Epoch 15/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0018 - accuracy: 0.2398 - val_loss: 2.0100 - val_accuracy: 0.2393\n",
            "Epoch 16/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9951 - accuracy: 0.2411 - val_loss: 2.0034 - val_accuracy: 0.2350\n",
            "Epoch 17/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9882 - accuracy: 0.2409 - val_loss: 1.9966 - val_accuracy: 0.2327\n",
            "Epoch 18/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9802 - accuracy: 0.2389 - val_loss: 1.9881 - val_accuracy: 0.2350\n",
            "Epoch 19/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9717 - accuracy: 0.2360 - val_loss: 1.9794 - val_accuracy: 0.2307\n",
            "Epoch 20/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9625 - accuracy: 0.2281 - val_loss: 1.9705 - val_accuracy: 0.2213\n",
            "Epoch 21/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9528 - accuracy: 0.2256 - val_loss: 1.9596 - val_accuracy: 0.2173\n",
            "Epoch 22/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9425 - accuracy: 0.2262 - val_loss: 1.9490 - val_accuracy: 0.2183\n",
            "Epoch 23/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9315 - accuracy: 0.2275 - val_loss: 1.9378 - val_accuracy: 0.2243\n",
            "Epoch 24/800\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 1.9197 - accuracy: 0.2316 - val_loss: 1.9252 - val_accuracy: 0.2293\n",
            "Epoch 25/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9074 - accuracy: 0.2353 - val_loss: 1.9127 - val_accuracy: 0.2300\n",
            "Epoch 26/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8951 - accuracy: 0.2371 - val_loss: 1.9003 - val_accuracy: 0.2330\n",
            "Epoch 27/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8829 - accuracy: 0.2387 - val_loss: 1.8883 - val_accuracy: 0.2317\n",
            "Epoch 28/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8709 - accuracy: 0.2417 - val_loss: 1.8762 - val_accuracy: 0.2380\n",
            "Epoch 29/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8590 - accuracy: 0.2490 - val_loss: 1.8648 - val_accuracy: 0.2450\n",
            "Epoch 30/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8470 - accuracy: 0.2640 - val_loss: 1.8532 - val_accuracy: 0.2647\n",
            "Epoch 31/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8352 - accuracy: 0.2780 - val_loss: 1.8415 - val_accuracy: 0.2857\n",
            "Epoch 32/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8238 - accuracy: 0.2937 - val_loss: 1.8305 - val_accuracy: 0.3030\n",
            "Epoch 33/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8124 - accuracy: 0.3127 - val_loss: 1.8197 - val_accuracy: 0.3257\n",
            "Epoch 34/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8011 - accuracy: 0.3345 - val_loss: 1.8096 - val_accuracy: 0.3453\n",
            "Epoch 35/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7898 - accuracy: 0.3505 - val_loss: 1.7987 - val_accuracy: 0.3523\n",
            "Epoch 36/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7786 - accuracy: 0.3641 - val_loss: 1.7873 - val_accuracy: 0.3647\n",
            "Epoch 37/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7674 - accuracy: 0.3753 - val_loss: 1.7762 - val_accuracy: 0.3740\n",
            "Epoch 38/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7554 - accuracy: 0.3851 - val_loss: 1.7644 - val_accuracy: 0.3800\n",
            "Epoch 39/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7433 - accuracy: 0.3946 - val_loss: 1.7535 - val_accuracy: 0.3900\n",
            "Epoch 40/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7322 - accuracy: 0.4037 - val_loss: 1.7435 - val_accuracy: 0.4017\n",
            "Epoch 41/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7216 - accuracy: 0.4138 - val_loss: 1.7339 - val_accuracy: 0.4073\n",
            "Epoch 42/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7115 - accuracy: 0.4241 - val_loss: 1.7247 - val_accuracy: 0.4170\n",
            "Epoch 43/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7019 - accuracy: 0.4328 - val_loss: 1.7167 - val_accuracy: 0.4283\n",
            "Epoch 44/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6923 - accuracy: 0.4395 - val_loss: 1.7085 - val_accuracy: 0.4353\n",
            "Epoch 45/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6834 - accuracy: 0.4471 - val_loss: 1.6991 - val_accuracy: 0.4447\n",
            "Epoch 46/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6747 - accuracy: 0.4536 - val_loss: 1.6912 - val_accuracy: 0.4517\n",
            "Epoch 47/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.6666 - accuracy: 0.4597 - val_loss: 1.6837 - val_accuracy: 0.4577\n",
            "Epoch 48/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6586 - accuracy: 0.4634 - val_loss: 1.6773 - val_accuracy: 0.4543\n",
            "Epoch 49/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6512 - accuracy: 0.4668 - val_loss: 1.6712 - val_accuracy: 0.4530\n",
            "Epoch 50/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6440 - accuracy: 0.4672 - val_loss: 1.6634 - val_accuracy: 0.4537\n",
            "Epoch 51/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6370 - accuracy: 0.4669 - val_loss: 1.6572 - val_accuracy: 0.4547\n",
            "Epoch 52/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6305 - accuracy: 0.4654 - val_loss: 1.6511 - val_accuracy: 0.4487\n",
            "Epoch 53/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6241 - accuracy: 0.4650 - val_loss: 1.6449 - val_accuracy: 0.4503\n",
            "Epoch 54/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6181 - accuracy: 0.4628 - val_loss: 1.6395 - val_accuracy: 0.4470\n",
            "Epoch 55/800\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 1.6123 - accuracy: 0.4616 - val_loss: 1.6338 - val_accuracy: 0.4463\n",
            "Epoch 56/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6069 - accuracy: 0.4594 - val_loss: 1.6288 - val_accuracy: 0.4437\n",
            "Epoch 57/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.6016 - accuracy: 0.4580 - val_loss: 1.6246 - val_accuracy: 0.4447\n",
            "Epoch 58/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5965 - accuracy: 0.4566 - val_loss: 1.6197 - val_accuracy: 0.4393\n",
            "Epoch 59/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5916 - accuracy: 0.4552 - val_loss: 1.6159 - val_accuracy: 0.4407\n",
            "Epoch 60/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5869 - accuracy: 0.4546 - val_loss: 1.6106 - val_accuracy: 0.4383\n",
            "Epoch 61/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5822 - accuracy: 0.4534 - val_loss: 1.6062 - val_accuracy: 0.4353\n",
            "Epoch 62/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5779 - accuracy: 0.4529 - val_loss: 1.6024 - val_accuracy: 0.4347\n",
            "Epoch 63/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5734 - accuracy: 0.4515 - val_loss: 1.5984 - val_accuracy: 0.4367\n",
            "Epoch 64/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5693 - accuracy: 0.4515 - val_loss: 1.5953 - val_accuracy: 0.4357\n",
            "Epoch 65/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5652 - accuracy: 0.4503 - val_loss: 1.5899 - val_accuracy: 0.4350\n",
            "Epoch 66/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5611 - accuracy: 0.4495 - val_loss: 1.5870 - val_accuracy: 0.4333\n",
            "Epoch 67/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5573 - accuracy: 0.4489 - val_loss: 1.5833 - val_accuracy: 0.4363\n",
            "Epoch 68/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5534 - accuracy: 0.4478 - val_loss: 1.5800 - val_accuracy: 0.4333\n",
            "Epoch 69/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5496 - accuracy: 0.4473 - val_loss: 1.5772 - val_accuracy: 0.4317\n",
            "Epoch 70/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5460 - accuracy: 0.4451 - val_loss: 1.5728 - val_accuracy: 0.4280\n",
            "Epoch 71/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5423 - accuracy: 0.4425 - val_loss: 1.5701 - val_accuracy: 0.4260\n",
            "Epoch 72/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5387 - accuracy: 0.4418 - val_loss: 1.5674 - val_accuracy: 0.4270\n",
            "Epoch 73/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5353 - accuracy: 0.4415 - val_loss: 1.5635 - val_accuracy: 0.4277\n",
            "Epoch 74/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5318 - accuracy: 0.4417 - val_loss: 1.5620 - val_accuracy: 0.4303\n",
            "Epoch 75/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5284 - accuracy: 0.4416 - val_loss: 1.5578 - val_accuracy: 0.4307\n",
            "Epoch 76/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5250 - accuracy: 0.4426 - val_loss: 1.5551 - val_accuracy: 0.4297\n",
            "Epoch 77/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5216 - accuracy: 0.4421 - val_loss: 1.5521 - val_accuracy: 0.4300\n",
            "Epoch 78/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5184 - accuracy: 0.4431 - val_loss: 1.5487 - val_accuracy: 0.4320\n",
            "Epoch 79/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5154 - accuracy: 0.4431 - val_loss: 1.5458 - val_accuracy: 0.4333\n",
            "Epoch 80/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5121 - accuracy: 0.4432 - val_loss: 1.5434 - val_accuracy: 0.4327\n",
            "Epoch 81/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5089 - accuracy: 0.4434 - val_loss: 1.5409 - val_accuracy: 0.4293\n",
            "Epoch 82/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5058 - accuracy: 0.4436 - val_loss: 1.5393 - val_accuracy: 0.4360\n",
            "Epoch 83/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5030 - accuracy: 0.4439 - val_loss: 1.5349 - val_accuracy: 0.4313\n",
            "Epoch 84/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4999 - accuracy: 0.4439 - val_loss: 1.5329 - val_accuracy: 0.4330\n",
            "Epoch 85/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4968 - accuracy: 0.4447 - val_loss: 1.5290 - val_accuracy: 0.4327\n",
            "Epoch 86/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4940 - accuracy: 0.4449 - val_loss: 1.5267 - val_accuracy: 0.4347\n",
            "Epoch 87/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4910 - accuracy: 0.4455 - val_loss: 1.5244 - val_accuracy: 0.4337\n",
            "Epoch 88/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4881 - accuracy: 0.4452 - val_loss: 1.5224 - val_accuracy: 0.4347\n",
            "Epoch 89/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4855 - accuracy: 0.4461 - val_loss: 1.5204 - val_accuracy: 0.4340\n",
            "Epoch 90/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4824 - accuracy: 0.4459 - val_loss: 1.5161 - val_accuracy: 0.4350\n",
            "Epoch 91/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4796 - accuracy: 0.4465 - val_loss: 1.5145 - val_accuracy: 0.4357\n",
            "Epoch 92/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4769 - accuracy: 0.4470 - val_loss: 1.5113 - val_accuracy: 0.4347\n",
            "Epoch 93/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4741 - accuracy: 0.4470 - val_loss: 1.5083 - val_accuracy: 0.4377\n",
            "Epoch 94/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4713 - accuracy: 0.4482 - val_loss: 1.5042 - val_accuracy: 0.4347\n",
            "Epoch 95/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4679 - accuracy: 0.4484 - val_loss: 1.5011 - val_accuracy: 0.4333\n",
            "Epoch 96/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4648 - accuracy: 0.4485 - val_loss: 1.4993 - val_accuracy: 0.4370\n",
            "Epoch 97/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4620 - accuracy: 0.4494 - val_loss: 1.4968 - val_accuracy: 0.4343\n",
            "Epoch 98/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4590 - accuracy: 0.4498 - val_loss: 1.4932 - val_accuracy: 0.4350\n",
            "Epoch 99/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4562 - accuracy: 0.4501 - val_loss: 1.4917 - val_accuracy: 0.4360\n",
            "Epoch 100/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4533 - accuracy: 0.4507 - val_loss: 1.4887 - val_accuracy: 0.4380\n",
            "Epoch 101/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4506 - accuracy: 0.4513 - val_loss: 1.4857 - val_accuracy: 0.4367\n",
            "Epoch 102/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4478 - accuracy: 0.4515 - val_loss: 1.4835 - val_accuracy: 0.4373\n",
            "Epoch 103/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4451 - accuracy: 0.4520 - val_loss: 1.4803 - val_accuracy: 0.4367\n",
            "Epoch 104/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4425 - accuracy: 0.4529 - val_loss: 1.4773 - val_accuracy: 0.4387\n",
            "Epoch 105/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4397 - accuracy: 0.4527 - val_loss: 1.4750 - val_accuracy: 0.4400\n",
            "Epoch 106/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4370 - accuracy: 0.4539 - val_loss: 1.4739 - val_accuracy: 0.4413\n",
            "Epoch 107/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4344 - accuracy: 0.4541 - val_loss: 1.4706 - val_accuracy: 0.4403\n",
            "Epoch 108/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4317 - accuracy: 0.4554 - val_loss: 1.4678 - val_accuracy: 0.4420\n",
            "Epoch 109/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4291 - accuracy: 0.4558 - val_loss: 1.4654 - val_accuracy: 0.4407\n",
            "Epoch 110/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4264 - accuracy: 0.4563 - val_loss: 1.4639 - val_accuracy: 0.4433\n",
            "Epoch 111/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4240 - accuracy: 0.4570 - val_loss: 1.4603 - val_accuracy: 0.4423\n",
            "Epoch 112/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4213 - accuracy: 0.4577 - val_loss: 1.4578 - val_accuracy: 0.4423\n",
            "Epoch 113/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4187 - accuracy: 0.4584 - val_loss: 1.4559 - val_accuracy: 0.4447\n",
            "Epoch 114/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4162 - accuracy: 0.4587 - val_loss: 1.4538 - val_accuracy: 0.4457\n",
            "Epoch 115/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4136 - accuracy: 0.4589 - val_loss: 1.4532 - val_accuracy: 0.4477\n",
            "Epoch 116/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4110 - accuracy: 0.4600 - val_loss: 1.4496 - val_accuracy: 0.4477\n",
            "Epoch 117/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4087 - accuracy: 0.4610 - val_loss: 1.4462 - val_accuracy: 0.4453\n",
            "Epoch 118/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4058 - accuracy: 0.4612 - val_loss: 1.4455 - val_accuracy: 0.4490\n",
            "Epoch 119/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4035 - accuracy: 0.4622 - val_loss: 1.4416 - val_accuracy: 0.4483\n",
            "Epoch 120/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.4009 - accuracy: 0.4633 - val_loss: 1.4396 - val_accuracy: 0.4520\n",
            "Epoch 121/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3983 - accuracy: 0.4641 - val_loss: 1.4372 - val_accuracy: 0.4520\n",
            "Epoch 122/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.3956 - accuracy: 0.4647 - val_loss: 1.4347 - val_accuracy: 0.4523\n",
            "Epoch 123/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.3930 - accuracy: 0.4657 - val_loss: 1.4331 - val_accuracy: 0.4500\n",
            "Epoch 124/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3904 - accuracy: 0.4665 - val_loss: 1.4307 - val_accuracy: 0.4533\n",
            "Epoch 125/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3878 - accuracy: 0.4676 - val_loss: 1.4265 - val_accuracy: 0.4533\n",
            "Epoch 126/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3850 - accuracy: 0.4685 - val_loss: 1.4248 - val_accuracy: 0.4547\n",
            "Epoch 127/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3825 - accuracy: 0.4692 - val_loss: 1.4224 - val_accuracy: 0.4560\n",
            "Epoch 128/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3799 - accuracy: 0.4702 - val_loss: 1.4209 - val_accuracy: 0.4573\n",
            "Epoch 129/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3772 - accuracy: 0.4716 - val_loss: 1.4173 - val_accuracy: 0.4580\n",
            "Epoch 130/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3745 - accuracy: 0.4724 - val_loss: 1.4152 - val_accuracy: 0.4607\n",
            "Epoch 131/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3719 - accuracy: 0.4739 - val_loss: 1.4118 - val_accuracy: 0.4623\n",
            "Epoch 132/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3694 - accuracy: 0.4744 - val_loss: 1.4103 - val_accuracy: 0.4620\n",
            "Epoch 133/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3666 - accuracy: 0.4757 - val_loss: 1.4089 - val_accuracy: 0.4640\n",
            "Epoch 134/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3642 - accuracy: 0.4770 - val_loss: 1.4048 - val_accuracy: 0.4657\n",
            "Epoch 135/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3615 - accuracy: 0.4776 - val_loss: 1.4025 - val_accuracy: 0.4667\n",
            "Epoch 136/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3589 - accuracy: 0.4791 - val_loss: 1.4010 - val_accuracy: 0.4653\n",
            "Epoch 137/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3562 - accuracy: 0.4803 - val_loss: 1.3976 - val_accuracy: 0.4670\n",
            "Epoch 138/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3535 - accuracy: 0.4816 - val_loss: 1.3963 - val_accuracy: 0.4687\n",
            "Epoch 139/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3509 - accuracy: 0.4828 - val_loss: 1.3938 - val_accuracy: 0.4693\n",
            "Epoch 140/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3484 - accuracy: 0.4846 - val_loss: 1.3903 - val_accuracy: 0.4703\n",
            "Epoch 141/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3457 - accuracy: 0.4856 - val_loss: 1.3879 - val_accuracy: 0.4737\n",
            "Epoch 142/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3430 - accuracy: 0.4870 - val_loss: 1.3863 - val_accuracy: 0.4737\n",
            "Epoch 143/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3404 - accuracy: 0.4889 - val_loss: 1.3834 - val_accuracy: 0.4763\n",
            "Epoch 144/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3379 - accuracy: 0.4905 - val_loss: 1.3802 - val_accuracy: 0.4797\n",
            "Epoch 145/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3353 - accuracy: 0.4915 - val_loss: 1.3779 - val_accuracy: 0.4803\n",
            "Epoch 146/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3327 - accuracy: 0.4938 - val_loss: 1.3760 - val_accuracy: 0.4813\n",
            "Epoch 147/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3301 - accuracy: 0.4957 - val_loss: 1.3737 - val_accuracy: 0.4823\n",
            "Epoch 148/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3273 - accuracy: 0.4983 - val_loss: 1.3730 - val_accuracy: 0.4850\n",
            "Epoch 149/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3248 - accuracy: 0.4998 - val_loss: 1.3704 - val_accuracy: 0.4880\n",
            "Epoch 150/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3222 - accuracy: 0.5028 - val_loss: 1.3662 - val_accuracy: 0.4883\n",
            "Epoch 151/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3196 - accuracy: 0.5062 - val_loss: 1.3650 - val_accuracy: 0.4920\n",
            "Epoch 152/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3169 - accuracy: 0.5084 - val_loss: 1.3641 - val_accuracy: 0.4977\n",
            "Epoch 153/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3145 - accuracy: 0.5121 - val_loss: 1.3602 - val_accuracy: 0.4990\n",
            "Epoch 154/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3118 - accuracy: 0.5153 - val_loss: 1.3576 - val_accuracy: 0.5043\n",
            "Epoch 155/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3094 - accuracy: 0.5199 - val_loss: 1.3547 - val_accuracy: 0.5113\n",
            "Epoch 156/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3067 - accuracy: 0.5243 - val_loss: 1.3524 - val_accuracy: 0.5123\n",
            "Epoch 157/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3042 - accuracy: 0.5279 - val_loss: 1.3498 - val_accuracy: 0.5190\n",
            "Epoch 158/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.3016 - accuracy: 0.5331 - val_loss: 1.3477 - val_accuracy: 0.5223\n",
            "Epoch 159/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2990 - accuracy: 0.5372 - val_loss: 1.3452 - val_accuracy: 0.5263\n",
            "Epoch 160/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2963 - accuracy: 0.5421 - val_loss: 1.3429 - val_accuracy: 0.5330\n",
            "Epoch 161/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2937 - accuracy: 0.5460 - val_loss: 1.3411 - val_accuracy: 0.5343\n",
            "Epoch 162/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2912 - accuracy: 0.5477 - val_loss: 1.3379 - val_accuracy: 0.5393\n",
            "Epoch 163/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2884 - accuracy: 0.5501 - val_loss: 1.3370 - val_accuracy: 0.5410\n",
            "Epoch 164/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2858 - accuracy: 0.5521 - val_loss: 1.3335 - val_accuracy: 0.5463\n",
            "Epoch 165/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2831 - accuracy: 0.5527 - val_loss: 1.3305 - val_accuracy: 0.5467\n",
            "Epoch 166/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2806 - accuracy: 0.5547 - val_loss: 1.3282 - val_accuracy: 0.5437\n",
            "Epoch 167/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2777 - accuracy: 0.5545 - val_loss: 1.3259 - val_accuracy: 0.5483\n",
            "Epoch 168/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2749 - accuracy: 0.5558 - val_loss: 1.3230 - val_accuracy: 0.5470\n",
            "Epoch 169/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2721 - accuracy: 0.5566 - val_loss: 1.3200 - val_accuracy: 0.5447\n",
            "Epoch 170/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2692 - accuracy: 0.5579 - val_loss: 1.3184 - val_accuracy: 0.5497\n",
            "Epoch 171/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2659 - accuracy: 0.5637 - val_loss: 1.3134 - val_accuracy: 0.5643\n",
            "Epoch 172/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2631 - accuracy: 0.5763 - val_loss: 1.3104 - val_accuracy: 0.5760\n",
            "Epoch 173/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2596 - accuracy: 0.5902 - val_loss: 1.3082 - val_accuracy: 0.5903\n",
            "Epoch 174/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2562 - accuracy: 0.6048 - val_loss: 1.3044 - val_accuracy: 0.6060\n",
            "Epoch 175/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2528 - accuracy: 0.6157 - val_loss: 1.3005 - val_accuracy: 0.6167\n",
            "Epoch 176/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2490 - accuracy: 0.6255 - val_loss: 1.2995 - val_accuracy: 0.6233\n",
            "Epoch 177/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2456 - accuracy: 0.6320 - val_loss: 1.2938 - val_accuracy: 0.6270\n",
            "Epoch 178/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2419 - accuracy: 0.6367 - val_loss: 1.2910 - val_accuracy: 0.6330\n",
            "Epoch 179/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2384 - accuracy: 0.6402 - val_loss: 1.2876 - val_accuracy: 0.6360\n",
            "Epoch 180/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2349 - accuracy: 0.6426 - val_loss: 1.2842 - val_accuracy: 0.6393\n",
            "Epoch 181/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2313 - accuracy: 0.6453 - val_loss: 1.2810 - val_accuracy: 0.6407\n",
            "Epoch 182/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2276 - accuracy: 0.6477 - val_loss: 1.2796 - val_accuracy: 0.6347\n",
            "Epoch 183/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2243 - accuracy: 0.6485 - val_loss: 1.2735 - val_accuracy: 0.6397\n",
            "Epoch 184/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2205 - accuracy: 0.6494 - val_loss: 1.2707 - val_accuracy: 0.6383\n",
            "Epoch 185/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2170 - accuracy: 0.6499 - val_loss: 1.2674 - val_accuracy: 0.6467\n",
            "Epoch 186/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2132 - accuracy: 0.6516 - val_loss: 1.2631 - val_accuracy: 0.6443\n",
            "Epoch 187/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2096 - accuracy: 0.6518 - val_loss: 1.2592 - val_accuracy: 0.6457\n",
            "Epoch 188/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2059 - accuracy: 0.6520 - val_loss: 1.2554 - val_accuracy: 0.6440\n",
            "Epoch 189/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2019 - accuracy: 0.6530 - val_loss: 1.2531 - val_accuracy: 0.6437\n",
            "Epoch 190/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1983 - accuracy: 0.6535 - val_loss: 1.2485 - val_accuracy: 0.6460\n",
            "Epoch 191/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.1945 - accuracy: 0.6535 - val_loss: 1.2450 - val_accuracy: 0.6460\n",
            "Epoch 192/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1906 - accuracy: 0.6543 - val_loss: 1.2416 - val_accuracy: 0.6460\n",
            "Epoch 193/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.1867 - accuracy: 0.6539 - val_loss: 1.2370 - val_accuracy: 0.6460\n",
            "Epoch 194/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1828 - accuracy: 0.6548 - val_loss: 1.2337 - val_accuracy: 0.6483\n",
            "Epoch 195/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1790 - accuracy: 0.6551 - val_loss: 1.2300 - val_accuracy: 0.6517\n",
            "Epoch 196/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1750 - accuracy: 0.6556 - val_loss: 1.2259 - val_accuracy: 0.6490\n",
            "Epoch 197/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1709 - accuracy: 0.6555 - val_loss: 1.2218 - val_accuracy: 0.6493\n",
            "Epoch 198/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1667 - accuracy: 0.6566 - val_loss: 1.2180 - val_accuracy: 0.6510\n",
            "Epoch 199/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1626 - accuracy: 0.6565 - val_loss: 1.2142 - val_accuracy: 0.6540\n",
            "Epoch 200/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1585 - accuracy: 0.6570 - val_loss: 1.2107 - val_accuracy: 0.6510\n",
            "Epoch 201/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1544 - accuracy: 0.6572 - val_loss: 1.2067 - val_accuracy: 0.6520\n",
            "Epoch 202/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1502 - accuracy: 0.6574 - val_loss: 1.2031 - val_accuracy: 0.6517\n",
            "Epoch 203/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1458 - accuracy: 0.6576 - val_loss: 1.1984 - val_accuracy: 0.6523\n",
            "Epoch 204/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1414 - accuracy: 0.6589 - val_loss: 1.1932 - val_accuracy: 0.6540\n",
            "Epoch 205/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1369 - accuracy: 0.6597 - val_loss: 1.1889 - val_accuracy: 0.6557\n",
            "Epoch 206/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1324 - accuracy: 0.6599 - val_loss: 1.1851 - val_accuracy: 0.6527\n",
            "Epoch 207/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1280 - accuracy: 0.6605 - val_loss: 1.1805 - val_accuracy: 0.6533\n",
            "Epoch 208/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.1231 - accuracy: 0.6611 - val_loss: 1.1761 - val_accuracy: 0.6557\n",
            "Epoch 209/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1185 - accuracy: 0.6614 - val_loss: 1.1725 - val_accuracy: 0.6530\n",
            "Epoch 210/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1133 - accuracy: 0.6623 - val_loss: 1.1662 - val_accuracy: 0.6550\n",
            "Epoch 211/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1082 - accuracy: 0.6626 - val_loss: 1.1601 - val_accuracy: 0.6567\n",
            "Epoch 212/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1029 - accuracy: 0.6633 - val_loss: 1.1554 - val_accuracy: 0.6550\n",
            "Epoch 213/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0978 - accuracy: 0.6638 - val_loss: 1.1503 - val_accuracy: 0.6563\n",
            "Epoch 214/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0926 - accuracy: 0.6647 - val_loss: 1.1456 - val_accuracy: 0.6567\n",
            "Epoch 215/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0876 - accuracy: 0.6657 - val_loss: 1.1404 - val_accuracy: 0.6560\n",
            "Epoch 216/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0822 - accuracy: 0.6662 - val_loss: 1.1362 - val_accuracy: 0.6570\n",
            "Epoch 217/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0767 - accuracy: 0.6665 - val_loss: 1.1307 - val_accuracy: 0.6593\n",
            "Epoch 218/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0710 - accuracy: 0.6671 - val_loss: 1.1240 - val_accuracy: 0.6603\n",
            "Epoch 219/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0646 - accuracy: 0.6675 - val_loss: 1.1174 - val_accuracy: 0.6600\n",
            "Epoch 220/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0580 - accuracy: 0.6688 - val_loss: 1.1105 - val_accuracy: 0.6617\n",
            "Epoch 221/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0508 - accuracy: 0.6689 - val_loss: 1.1033 - val_accuracy: 0.6627\n",
            "Epoch 222/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0433 - accuracy: 0.6697 - val_loss: 1.0949 - val_accuracy: 0.6633\n",
            "Epoch 223/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0354 - accuracy: 0.6702 - val_loss: 1.0866 - val_accuracy: 0.6643\n",
            "Epoch 224/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0275 - accuracy: 0.6711 - val_loss: 1.0790 - val_accuracy: 0.6663\n",
            "Epoch 225/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0192 - accuracy: 0.6715 - val_loss: 1.0719 - val_accuracy: 0.6653\n",
            "Epoch 226/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0109 - accuracy: 0.6715 - val_loss: 1.0639 - val_accuracy: 0.6673\n",
            "Epoch 227/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0023 - accuracy: 0.6736 - val_loss: 1.0557 - val_accuracy: 0.6673\n",
            "Epoch 228/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9941 - accuracy: 0.6740 - val_loss: 1.0481 - val_accuracy: 0.6650\n",
            "Epoch 229/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9858 - accuracy: 0.6741 - val_loss: 1.0409 - val_accuracy: 0.6687\n",
            "Epoch 230/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9780 - accuracy: 0.6747 - val_loss: 1.0334 - val_accuracy: 0.6677\n",
            "Epoch 231/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9703 - accuracy: 0.6755 - val_loss: 1.0263 - val_accuracy: 0.6707\n",
            "Epoch 232/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9629 - accuracy: 0.6767 - val_loss: 1.0186 - val_accuracy: 0.6703\n",
            "Epoch 233/800\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.9558 - accuracy: 0.6779 - val_loss: 1.0116 - val_accuracy: 0.6707\n",
            "Epoch 234/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9492 - accuracy: 0.6786 - val_loss: 1.0052 - val_accuracy: 0.6723\n",
            "Epoch 235/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9428 - accuracy: 0.6798 - val_loss: 1.0005 - val_accuracy: 0.6740\n",
            "Epoch 236/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9369 - accuracy: 0.6809 - val_loss: 0.9942 - val_accuracy: 0.6763\n",
            "Epoch 237/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9314 - accuracy: 0.6822 - val_loss: 0.9895 - val_accuracy: 0.6777\n",
            "Epoch 238/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9262 - accuracy: 0.6833 - val_loss: 0.9857 - val_accuracy: 0.6767\n",
            "Epoch 239/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9213 - accuracy: 0.6866 - val_loss: 0.9800 - val_accuracy: 0.6783\n",
            "Epoch 240/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9165 - accuracy: 0.6878 - val_loss: 0.9763 - val_accuracy: 0.6833\n",
            "Epoch 241/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9120 - accuracy: 0.6892 - val_loss: 0.9722 - val_accuracy: 0.6840\n",
            "Epoch 242/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9075 - accuracy: 0.6899 - val_loss: 0.9678 - val_accuracy: 0.6827\n",
            "Epoch 243/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.9029 - accuracy: 0.6924 - val_loss: 0.9633 - val_accuracy: 0.6800\n",
            "Epoch 244/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8986 - accuracy: 0.6937 - val_loss: 0.9598 - val_accuracy: 0.6840\n",
            "Epoch 245/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8946 - accuracy: 0.6965 - val_loss: 0.9586 - val_accuracy: 0.6897\n",
            "Epoch 246/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8906 - accuracy: 0.6991 - val_loss: 0.9531 - val_accuracy: 0.6883\n",
            "Epoch 247/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8864 - accuracy: 0.7016 - val_loss: 0.9497 - val_accuracy: 0.6923\n",
            "Epoch 248/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8824 - accuracy: 0.7047 - val_loss: 0.9448 - val_accuracy: 0.6920\n",
            "Epoch 249/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8784 - accuracy: 0.7067 - val_loss: 0.9413 - val_accuracy: 0.6967\n",
            "Epoch 250/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8743 - accuracy: 0.7096 - val_loss: 0.9383 - val_accuracy: 0.6957\n",
            "Epoch 251/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8704 - accuracy: 0.7125 - val_loss: 0.9350 - val_accuracy: 0.7007\n",
            "Epoch 252/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8666 - accuracy: 0.7153 - val_loss: 0.9325 - val_accuracy: 0.7063\n",
            "Epoch 253/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8627 - accuracy: 0.7188 - val_loss: 0.9294 - val_accuracy: 0.7103\n",
            "Epoch 254/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8588 - accuracy: 0.7232 - val_loss: 0.9250 - val_accuracy: 0.7160\n",
            "Epoch 255/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8551 - accuracy: 0.7286 - val_loss: 0.9217 - val_accuracy: 0.7217\n",
            "Epoch 256/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8513 - accuracy: 0.7343 - val_loss: 0.9187 - val_accuracy: 0.7250\n",
            "Epoch 257/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8473 - accuracy: 0.7390 - val_loss: 0.9142 - val_accuracy: 0.7293\n",
            "Epoch 258/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8435 - accuracy: 0.7456 - val_loss: 0.9110 - val_accuracy: 0.7313\n",
            "Epoch 259/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8396 - accuracy: 0.7507 - val_loss: 0.9089 - val_accuracy: 0.7420\n",
            "Epoch 260/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8358 - accuracy: 0.7564 - val_loss: 0.9052 - val_accuracy: 0.7523\n",
            "Epoch 261/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8321 - accuracy: 0.7645 - val_loss: 0.9012 - val_accuracy: 0.7537\n",
            "Epoch 262/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8282 - accuracy: 0.7702 - val_loss: 0.8978 - val_accuracy: 0.7607\n",
            "Epoch 263/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8244 - accuracy: 0.7775 - val_loss: 0.8943 - val_accuracy: 0.7640\n",
            "Epoch 264/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8205 - accuracy: 0.7832 - val_loss: 0.8902 - val_accuracy: 0.7693\n",
            "Epoch 265/800\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.8166 - accuracy: 0.7890 - val_loss: 0.8872 - val_accuracy: 0.7760\n",
            "Epoch 266/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8129 - accuracy: 0.7944 - val_loss: 0.8830 - val_accuracy: 0.7767\n",
            "Epoch 267/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8089 - accuracy: 0.7975 - val_loss: 0.8798 - val_accuracy: 0.7767\n",
            "Epoch 268/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8052 - accuracy: 0.8008 - val_loss: 0.8757 - val_accuracy: 0.7847\n",
            "Epoch 269/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8012 - accuracy: 0.8037 - val_loss: 0.8738 - val_accuracy: 0.7883\n",
            "Epoch 270/800\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.7975 - accuracy: 0.8047 - val_loss: 0.8692 - val_accuracy: 0.7887\n",
            "Epoch 271/800\n",
            "1083/1875 [================>.............] - ETA: 3s - loss: 0.7999 - accuracy: 0.8044"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cafa9e41483d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m            callbacks=[tensorflow_c])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx6jixT0l1T1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd6886ff-535f-46e7-9dd2-b5498af18b21"
      },
      "source": [
        "y_pred=model.predict(X_cv,verbose=True)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "con_mat = tf.math.confusion_matrix(labels=y_cv, predictions=y_pred).numpy()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGhPDC7vmGhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "confusion_matrix(y_cv, y_pred)\n",
        "precision_score(y_cv, y_pred, average='micro')\n",
        "f1_score(y_cv,y_pred,average='macro')\n",
        "cohen_kappa_score(y_cv, y_pred)\n",
        "model.save(\"m_tarea.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}